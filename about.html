<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta
            name="description"
            content="Visualizer of BERT's Attention Mechanism and analyser of adversarial attacks."
        />
        <meta
            name="keywords"
            content="BERT,Attention,Adversarial Attack,Shortcut Learning, DistilBERT,NLP"
        />
        <title>Attentive BERT</title>
        <link
            rel="icon"
            type="image/png"
            href="./resources/favicon.png"
        />
        <link
            rel="stylesheet"
            href="./resources/style.css"
        />
        <script
            src="./resources/script.js"
            defer
        ></script>
    </head>
    <body>
        <nav aria-label="Navbar" class="navbar navbar-expand-md navbar-light bg-light">
    <div class="container-md">
        <div class="navbar-leftmost">
            <button
                aria-controls="navbarContent"
                aria-expanded="false"
                aria-label="Toggle navigation"
                class="navbar-toggler"
                data-bs-target="#navbarContent"
                data-bs-toggle="collapse"
                type="button"
            >
                <span class="navbar-toggler-icon">
                </span>
            </button>
            <a class="navbar-brand" href="./">
                <img src="./resources/img/logo.png"> Attentive<strong>BERT</strong>
            </a>
        </div>
        <div class="collapse navbar-collapse" id="navbarContent">
            <ul class="navbar-nav me-auto">
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" aria-expanded="false">Learn</a>
                    <ul class="dropdown-menu navbar-dropdown-animation">
                        <li><a class="dropdown-item" href="./learn/bert.html">BERT</a></li>
                        <li><a class="dropdown-item" href="./learn/attention.html">Self-Attention mechanism</a></li>
                        <li><a class="dropdown-item" href="./learn/nli.html">Natural Language Inference (NLI)</a></li>
                        <li><a class="dropdown-item" href="./learn/ari.html">Argumentative Relation Identification (ARI)</a></li>
                        <li><a class="dropdown-item" href="./learn/fv.html">Fact Verification (FV)</a></li>
                        <li><a class="dropdown-item" href="./learn/shortcut_learning.html">Shortcut learning</a></li>
                    </ul>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" aria-expanded="false">Visualize</a>
                    <ul class="dropdown-menu navbar-dropdown-animation">
                        <li><a class="dropdown-item" href="./visualize/attention_heatmaps.html">Attention weights (Single input)</a></li>
                        <li><a class="dropdown-item" href="./visualize/compare_attention.html">Compare attention weights (Two inputs)</a></li>
                    </ul>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="./adversarial_attacks.html">
                        Adversarial Attacks
                    </a>
                </li>
            </ul>
            <ul class="navbar-nav">
                <li class="nav-item">
                    <a class="nav-link" href="./about.html">
                        About
                    </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/Goncalerta/AttentiveBERT">
                        <i class="bi bi-github"></i>
                    </a>
                </li>
            </ul>
        </div>
    </div>
</nav>
<div class="container-xl my-md-4">
    <main class="mx-5">
      <div class="article-intro ps-lg-4">
        <h1 class="article-title" id="content">About</h1>
        <p class="article-lead">AttentiveBERT is designed to make the visualization of attention weights of BERT-based models more intuitive and convenient, particularly for the case of adversarial attacks.</p>
      </div>
      <div class="article-content ps-lg-4 mt-3">
        <p>
            This website was developed by Pedro Gonçalo Correia for the curricular unit <em>Capstone Project</em> at 
            <a href="https://fe.up.pt/">Faculdade de Engenharia da Universidade do Porto</a>, as well as the 
            <a href="https://gulbenkian.pt/">Gulbenkian Foundation</a>'s <em>New Talents in Artificial Inteligence</em> program.
        </p>
        <p>
            The website's main goal is to facilitate the visualization of attention weights in BERT-based models, allowing the user
            to input one pair of sentences (or two pairs, and then compare them), see the model predictions, and inspect the attention
            weights of each head and layer, as well as the mean value of the attention weights in all heads for a single layer or vice-versa and
            the mean value of the attention weights in all layers and all heads. The website is designed to work with the NLP classification
            tasks of Natural Language Inference, Argumentative Relation Identification, and Fact Verification. 
        </p>
        <p>
            It is also possible to generate adversarial attacks using one of many methods in the literature, such as <a href="https://arxiv.org/abs/1907.11932">TextFooler</a> or <a href="https://arxiv.org/abs/2004.09984">BERT-Attack</a>.
            Since generating adversarial attacks takes a long time, and in many cases no successful attack is found for an input pair of sentences,
            a list of pregenerated attacks is also provided. The input before and after the adversarial attack may be compared with the visualization
            of attention weights.
        </p>
        <p>
            This website also has a didatic component, with an explanation of the main concepts related to the research problem's theme (<em>Explaining
            Shortcut Learning Through Attention Models</em>) that are also relevant to the website, as well as tooltips and guides in the visualization 
            pages to help the user understand how to use the website and the concepts they are interacting with.
        </p>
      </div>
    </main>
  </div>
 <div class="container mt-4">
    <hr>
    <footer>
        <p class="mb-0 copyright">Copyright &copy; Pedro Gonçalo Correia 2022</p>
        <p class="mb-0 copyright">This website and its content is licensed under the <a href="https://github.com/Goncalerta/AttentiveBERT/blob/main/LICENSE">GNU GENERAL PUBLIC LICENSE v3</a>.</p>
        <ul class="nav">
            <li class="nav-item">
                <a class="nav-link ps-0" href="mailto: pedrogoncalocorreia@hotmail.com"><i class="bi bi-envelope"></i> pedrogoncalocorreia@hotmail.com</a>
            </li>
            <li class="nav-item">
                <a class="nav-link ps-0" href="https://github.com/Goncalerta"><i class="bi bi-github"></i> Github</a>
            </li>
            <li class="nav-item">
                <a class="nav-link ps-0" href="https://www.linkedin.com/in/pedro-goncalo-correia/"><i class="bi bi-linkedin"></i> Linkedin</a>
            </li>
        </ul>
    </footer>
</div>
    </body>
</html>
